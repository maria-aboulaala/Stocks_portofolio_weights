{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import shapiro\n",
    "from scipy.optimize import minimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[*********************100%%**********************]  5 of 5 completed\n",
      "Test de normalité pour AAPL: Statistique=0.9396017789840698, p-value=1.1503578534188819e-08\n",
      "Test de normalité pour MSFT: Statistique=0.911160409450531, p-value=4.41174770327013e-11\n",
      "Test de normalité pour GOOGL: Statistique=0.9328373670578003, p-value=2.692721601249559e-09\n",
      "Test de normalité pour AMZN: Statistique=0.9804868698120117, p-value=0.0015486348420381546\n",
      "Test de normalité pour TSLA: Statistique=0.9601470232009888, p-value=1.918489715535543e-06\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Liste de symboles de stocks aléatoires\n",
    "stocks = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']\n",
    "\n",
    "# Télécharger les données des stocks à l'aide de yfinance\n",
    "data = yf.download(stocks, start=\"2020-01-01\", end=\"2021-01-01\")\n",
    "\n",
    "# Calcul des rendements quotidiens\n",
    "returns = data['Adj Close'].pct_change().dropna()\n",
    "\n",
    "# Calcul de statistiques\n",
    "mean_returns = returns.mean()\n",
    "cov_matrix = returns.cov()\n",
    "\n",
    "# Test de normalité (test de Shapiro-Wilk)\n",
    "for stock in stocks:\n",
    "    stat, p = shapiro(returns[stock])\n",
    "    print(f\"Test de normalité pour {stock}: Statistique={stat}, p-value={p}\")\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "# Détermination de la variance minimale\n",
    "def minimize_variance(weights):\n",
    "    return np.sqrt(np.dot(weights.T, np.dot(cov_matrix, weights)))\n",
    "\n",
    "# Contraintes d'allocation\n",
    "constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
    "\n",
    "# Bornes des poids\n",
    "bounds = tuple((0, 1) for stock in range(len(stocks)))\n",
    "\n",
    "# Initialisation des poids égaux\n",
    "initial_weights = len(stocks) * [1. / len(stocks)]\n",
    "\n",
    "# Optimisation pour la variance minimale\n",
    "min_var_portfolio = minimize(minimize_variance, initial_weights, method='SLSQP', bounds=bounds, constraints=constraints)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Poids du portefeuille à variance minimale:\n",
      "AAPL: 0.0\n",
      "MSFT: 0.5432539410112296\n",
      "GOOGL: 0.4567460589887703\n",
      "AMZN: 0.0\n",
      "TSLA: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Poids du portefeuille à variance minimale:\")\n",
    "for i in range(len(stocks)):\n",
    "    print(f\"{stocks[i]}: {min_var_portfolio.x[i]}\")\n",
    "\n",
    "# Création de la frontière efficiente\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def efficient_frontier(returns):\n",
    "    num_assets = len(returns.columns)\n",
    "    results = np.zeros((4, num_assets))\n",
    "    \n",
    "    for i in range(num_assets):\n",
    "        weights = np.array([1 / num_assets] * num_assets)\n",
    "        \n",
    "        def portfolio_variance(weights):\n",
    "            return np.sqrt(np.dot(weights.T, np.dot(returns.cov(), weights)))\n",
    "        \n",
    "        constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
    "        \n",
    "        bounds = tuple((0, 1) for asset in range(num_assets))\n",
    "        \n",
    "        result = minimize(portfolio_variance, weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "        \n",
    "        portfolio_stddev = result.fun\n",
    "        portfolio_return = np.sum(weights * returns.mean()) * 252\n",
    "        \n",
    "        results[0, i] = portfolio_stddev\n",
    "        results[1, i] = portfolio_return\n",
    "        results[2, i] = portfolio_return / portfolio_stddev\n",
    "        results[3, i] = weights\n",
    "        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def efficient_frontier(returns):\n",
    "    num_assets = len(returns.columns)\n",
    "    results = np.zeros((4, num_assets), dtype=object)  # Use dtype=object for non-homogeneous data\n",
    "    \n",
    "    for i in range(num_assets):\n",
    "        weights = np.array([1 / num_assets] * num_assets)  # Convert to NumPy array\n",
    "        \n",
    "        def portfolio_variance(weights):\n",
    "            return np.sqrt(np.dot(weights.T, np.dot(returns.cov(), weights)))\n",
    "        \n",
    "        constraints = ({'type': 'eq', 'fun': lambda weights: np.sum(weights) - 1})\n",
    "        \n",
    "        bounds = tuple((0, 1) for asset in range(num_assets))\n",
    "        \n",
    "        result = minimize(portfolio_variance, weights, method='SLSQP', bounds=bounds, constraints=constraints)\n",
    "        \n",
    "        portfolio_stddev = result.fun\n",
    "        portfolio_return = np.sum(weights * returns.mean()) * 252\n",
    "        \n",
    "        results[0, i] = portfolio_stddev\n",
    "        results[1, i] = portfolio_return\n",
    "        results[2, i] = portfolio_return / portfolio_stddev\n",
    "        results[3, i] = result.x  # Assign the optimized weights as a NumPy array\n",
    "        \n",
    "    return results\n",
    "\n",
    "efficient_frontier_data = efficient_frontier(returns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "efficient_frontier_df = pd.DataFrame(efficient_frontier_data.T, columns=[\"Risk\", \"Return\", \"Sharpe Ratio\", \"Weights\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frontière efficiente:\n",
      "       Risk    Return Sharpe Ratio  \\\n",
      "0  0.022208  0.913813    41.147686   \n",
      "1  0.022208  0.913813    41.147686   \n",
      "2  0.022208  0.913813    41.147686   \n",
      "3  0.022208  0.913813    41.147686   \n",
      "4  0.022208  0.913813    41.147686   \n",
      "\n",
      "                                             Weights  \n",
      "0  [0.0, 0.5432539410112296, 0.4567460589887703, ...  \n",
      "1  [0.0, 0.5432539410112296, 0.4567460589887703, ...  \n",
      "2  [0.0, 0.5432539410112296, 0.4567460589887703, ...  \n",
      "3  [0.0, 0.5432539410112296, 0.4567460589887703, ...  \n",
      "4  [0.0, 0.5432539410112296, 0.4567460589887703, ...  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Frontière efficiente:\")\n",
    "print(efficient_frontier_df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
